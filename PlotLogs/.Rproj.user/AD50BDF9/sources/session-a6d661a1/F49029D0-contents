---
title: "ShowLogs"
format:
  html: 
    code-tools:
      source: true
      toggle: false
      caption: none
server: shiny
editor: visual
author: Carl Fortelius, v0 March 2023
---

## Quarto

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)


```

This piece of software can access and examine log-files generated by the Harmonie-arome, and display results on a shiny interface. Unfortunately rendering the document in rstudio will not work, but executing chunk by chunk inside rstudio does. See the last chunk of code

Here load needed libraries

```{r initialize}
#library(harp)
library(tidyverse)
library(here)
library(XML)
library(rvest)
library(hms)
library(stringr)        
library(httr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(shiny)
library(shinyFiles)
#library(shinythemes)

```

Define a function to count the number of minimization loop, based on the iteration counter in 4d-var logs

```{r}
Nloop <- function(x){
m <- 0*x  
m[ which( diff(x)<0 ) +1 ] <- 1
+ cumsum(m) +  1 
}
```

Define a function to return a tibble of cost functions parsed from HM_DATE

```{r }
# We are lookibng for lines beginning like this: GREPCOST - ITER,SIM,JO,JB,JC,JQ,JP,JA 
get_cost_functions <- function(HM_DATE){
  
if ( any(str_detect(HM_DATE, "4DVminim")) ) {
  #This contains  output from a 4D-VAR minimization
  idx_cost <- which(str_detect(HM_DATE, "Estimated quadratic cost"))
  idx_grad <- which(str_detect(HM_DATE, "Estimated gradient norm"))
  tibble(
    ITER = sapply(idx_cost, function(idx_cost) 
      if( str_detect(HM_DATE[[idx_cost]],"Iteration") ){
        as.numeric( str_extract(HM_DATE[[idx_cost]],"\\(?[0-9.]+\\)?") )
      } else{
        0
      }
    ),
    COST = sapply(idx_cost, function(idx_cost) 
      if( str_detect(HM_DATE[[idx_cost]],"Iteration") ){
        as.numeric(unlist(strsplit(HM_DATE[[idx_cost]]," +") )[9] ) 
      } else{
        as.numeric(unlist(strsplit(HM_DATE[[idx_cost]]," +") )[10] ) 
      }
    ),
    
    GRADx10 = sapply(idx_grad, function(idx_grad) 
      if( str_detect(HM_DATE[[idx_grad]],"Iteration") ){
        as.numeric(unlist(strsplit(HM_DATE[[idx_grad]]," +") )[9] ) * 10.
      } else{
        as.numeric(unlist(strsplit(HM_DATE[[idx_grad]]," +") )[10] ) * 10
      }
    ),
    LOOP = Nloop(ITER)
)
  
} else if (any(str_detect(HM_DATE, "GREPCOST")) ){ 
  #output from 3D-VAR minimization
  idx <- which(str_detect(HM_DATE, "GREPCOST "))
  idx <- idx[seq(2,length(idx)-1)] #Don't know if this isi ok, really
  tibble(
   ITER = sapply(idx, function(idx)
     as.numeric(unlist(str_extract_all(HM_DATE[[idx]],"\\(?[0-9.]+\\)?") )[1] ) ),
   #SIM = sapply(idx, function(idx)
    # as.numeric(unlist(str_extract_all(HM_DATE[[idx]],"\\(?[0-9.]+\\)?") )[2] )),
   JO = sapply(idx, function(idx)
     as.numeric(unlist(str_extract_all(HM_DATE[[idx]],"\\(?[0-9.]+\\)?") )[3] )),
   JB = sapply(idx, function(idx)
     as.numeric(unlist(str_extract_all(HM_DATE[[idx]],"\\(?[0-9.]+\\)?") )[4] )),
   JC = sapply(idx, function(idx)
     as.numeric(unlist(str_extract_all(HM_DATE[[idx]],"\\(?[0-9.]+\\)?") )[5] )),
   JQ = sapply(idx, function(idx)
     as.numeric(unlist(str_extract_all(HM_DATE[[idx]],"\\(?[0-9.]+\\)?") )[6] )),
   JP = sapply(idx, function(idx)
     as.numeric(unlist(str_extract_all(HM_DATE[[idx]],"\\(?[0-9.]+\\)?") )[7] )),
   JA = sapply(idx+1, function(idx)
     as.numeric(unlist(str_extract_all(HM_DATE[[idx+1]],"\\(?[0-9.]+\\)?") )[1] )),
   J = JO + JB + JC + JQ + JP + JA
)
} else {
  # no D/A 
  return() }
}
#sapply(idx, function(idx) HM_DATE[[idx]])

```

Define a function to return a tibble of spectral norms parsed from HM_DATE

```{r}
get_spectral_norms <- function(HM_DATE){
  
#Find where the Forecast log starts
idf <- which(str_detect(HM_DATE, "Forecasting/Forecast"))[2]
#Find lines with value of NSTEP, and select those where NSTEP>0
idx <- which(str_detect(HM_DATE, "NORMS AT NSTEP CNT4"))
idx <- idx[idx > idf]
idx <- idx[ which(sapply(idx, function(idx) 
       as.numeric(str_extract_all(HM_DATE[[idx]],"\\(?[0-9,.]+\\)?")[[1]][[2]]) ) >0)  ]

tibble(
  NSTEP=sapply(idx, function(idx) as.numeric(str_extract_all(HM_DATE[[idx]],"\\(?[0-9,.]+\\)?")[[1]][[2]]) ),
  LOG_PREHYDS= sapply( idx, function(idx) as.numeric(str_extract( HM_DATE[[idx+1]], "\\(?[0-9,.]+\\)?"))),
  VORTICITY=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+3]]," +"))[[3]])),
  DIVERGENCE=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+3]]," +"))[[4]])),
  TEMPERATURE=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+3]]," +"))[[5]])),
  KINETIC_ENERGY=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+3]]," +"))[[6]])),
  LOG_PRE_PREHYD   = sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+5]]," +"))[[3]])),
  VERT_DIV_PLUS_X  =sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+5]]," +"))[[4]]))
) 
}


```

Define a function to return a tibble of grid point norms parsed from HM_DATE

Find lines with value of NSTEP, and select those where NSTEP\>0

```{r }

get_grid_point_norms <- function(HM_DATE){
#Find where the Forecast log starts
idf <- which(str_detect(HM_DATE, "Forecasting/Forecast"))[2]
#Find lines with value of NSTEP, and select those where NSTEP>0
idx <- which(str_detect(HM_DATE, "NORMS AT NSTEP CNT4"))
idx <- idx[idx > idf]
idx <- idx[ which(sapply(idx, function(idx) 
       as.numeric(str_extract_all(HM_DATE[[idx]],"\\(?[0-9,.]+\\)?")[[1]][[2]]) ) >0)  ]

  tibble(
  NSTEP=sapply(idx, function(idx) as.numeric(str_extract_all(HM_DATE[[idx]],"\\(?[0-9,.]+\\)?")[[1]][[2]]) ),
  SPECHUM=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+7]]," +"))[[3]])),
  SPECHUM_MIN=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+7]]," +"))[[4]])),
  SPECHUM_MAX=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+7]]," +"))[[5]])),
  
  LIQ_WATER=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+9]]," +"))[[3]])),
  LIQ_WATER_MIN=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+9]]," +"))[[4]])),
  LIQ_WATER_MAX=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+9]]," +"))[[5]])),

  SOL_WATER=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+11]]," +"))[[3]])),
  SOL_WATER_MIN=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+11]]," +"))[[4]])),
  SOL_WATER_MAX=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+11]]," +"))[[5]])),

  SNOW=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+13]]," +"))[[3]])),
  SNOW_MIN=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+13]]," +"))[[4]])),
  SNOW_MAX=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+13]]," +"))[[5]])),
  
  RAIN=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+15]]," +"))[[3]])),
  RAIN_MIN=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+15]]," +"))[[4]])),
  RAIN_MAX=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+15]]," +"))[[5]])),
  
  GRAUPEL=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+17]]," +"))[[3]])),
  GRAUPEL_MIN=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+17]]," +"))[[4]])),
  GRAUPEL_MAX=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+17]]," +"))[[5]])),

  TKE=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+19]]," +"))[[3]])),
  TKE_MIN=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+19]]," +"))[[4]])),
  TKE_MAX=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+19]]," +"))[[5]])),

  CLOUDFRAC=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+21]]," +"))[[3]])),
  CLOUDFRAC_MIN=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+21]]," +"))[[4]])),
  CLOUDFRAC_MAX=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+21]]," +"))[[5]])),
  
  SRC=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+23]]," +"))[[3]])),
  SRC_MIN=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+23]]," +"))[[4]])),
  SRC_MAX=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+23]]," +"))[[5]])),
  
  EZDIAG01=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+25]]," +"))[[3]])),
  EZDIAG01_MIN=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+25]]," +"))[[4]])),
  EZDIAG01_MAX=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+25]]," +"))[[5]])),
  
  EZDIAG02=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+27]]," +"))[[3]])),
  EZDIAG02_MIN=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+27]]," +"))[[4]])),
  EZDIAG02_MAX=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+27]]," +"))[[5]])),
  
  EZDIAG03=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+29]]," +"))[[3]])),
  EZDIAG03_MIN=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+29]]," +"))[[4]])),
  EZDIAG03_MAX=sapply( idx, function(idx) as.numeric(unlist(strsplit(HM_DATE[[idx+29]]," +"))[[5]]))
)
}

```

Define a function make_date_list to generate a list of log-files including path and all

```{r}
make_date_list <- function(start=2023031500, end=2023031600, by=24,
                  #path="https://metcoop.smhi.se/monitoring/msms/data/meps/",
                  path="/home/forteliu/Bologna/eei/hm_home/meps43_doppler/archive/log/",
                  prefix="HM_Date_", postfix=".html"){ # "_1_se.html") {
from <- as.POSIXct(paste(substr(start,1,4),"-",substr(start,5,6),"-",substr(start,7,8), 
               " ",substr(start,9,10),":00",sep=""),tz="UTC")
to <- as.POSIXct(paste(substr(end,1,4),"-",substr(end,5,6),"-",substr(end,7,8), 
               " ",substr(end,9,10),":00",sep=""),tz="UTC")

dtgs <- seq(from=from,by=as.numeric(by)*60*60,to=to)

sapply(dtgs, function(x)
        paste(path, prefix, format(x, format="%Y%m%d%H"),postfix, sep="")
)#dtgs
} #make_date_list  

```

Define a function get_data to access a HM_date-file and return a list of tibbles containing spectral norms and grid-point norms.

```{r}
get_data <- function(logfile){
  if( TRUE)  { #file.exists(logfile)){
    print(paste("working with file: ",basename(logfile)))
    HM_DATE <- try(unlist( strsplit(html_text(
    read_html(x = logfile,encoding="UTF-8")), '\n')))
    #cost <- get_cost_functions(HM_DATE)
    spectral <- try(get_spectral_norms(HM_DATE))
    gridpoint <- try(get_grid_point_norms(HM_DATE))
    if(nrow(spectral) > 0 & nrow(gridpoint) > 0) {
        #print(basename(logfile))  
        return(list(spectral,gridpoint)) 
    } else { 
        print(paste("Skipping bad or non-existing file",basename(logfile))) 
        return()
      }
  } else {
      print(paste("Skipping non-existent file",basename(logfile)))
      return()
  }
} 
```

Define the client side

```{r }
#Define the client side
ui <- fluidPage(
  #theme = shinytheme("darkly"),
  sidebarLayout(
    sidebarPanel(
      textInput("start", "DTGSTART",
         "2023031500"),
      textInput("end", "DTGEND",
         "2023031600"),
      textInput("by", "BY HOURS",
         "24"),
      textInput("path", "PATH",
         "https://metcoop.smhi.se/monitoring/msms/data/meps/"),
      textInput("prefix", "PREFIX",
         "HM_Date_"),
      textInput("postfix", "POSTFIX",
         "_1_se.html"),
      
      actionButton("read", "Load"),
      textOutput("update_info"),
      
      tabsetPanel(id = "tabset",
        tabPanel("Spectral norms",
            selectInput("spnorms", "Spectral norm", 
            choices = c(NULL))
         ),
         tabPanel("Grid point norms",
            selectInput("gpnorms", "Grid point norm", 
                    choices = c(NULL))
         ), 
      ), #tabset panel
   
      selectInput("showzero", "Show zero Y", 
                    choices = c("yes","no") ),
      
      actionButton("go", "Plot"),
 
    ), #sidebarPanel
    mainPanel(
     plotOutput("plot")
    )
  )
)


```

Define the server side

```{r}
# Define the server side
#| context: server
server <- function(input, output,session) {

    #shinyDirChoose(input, 'folder', roots=c(wd='.'), filetypes=c('', 'html, txt'))
    #observe({
     #print(input$folder)})
v <- reactiveValues(doPlot = FALSE,
                    doRead = FALSE)

 observeEvent(input$read, {
    v$doRead <- input$read
  })  
  observeEvent(input$tabset, {
    v$doRead <- FALSE
  })  
  observeEvent(input$start, {
    v$doRead <- FALSE
  })  
  observeEvent(input$end, {
    v$doRead <- FALSE
  })  
  observeEvent(input$by, {
    v$doRead <- FALSE
  })  
  observeEvent(input$path, {
    v$doRead <- FALSE
  })  
  observeEvent(input$prefix, {
    v$doRead <- FALSE
  })  
  observeEvent(input$postfix, {
    v$doRead <- FALSE
  }) 



 observeEvent(input$go, {
    v$doPlot <- input$go
  })

  observeEvent(input$tabset, {
    v$doPlot <- FALSE
  })  

output$update_info <- renderText({
  if (v$doRead == FALSE) return()
    #isolate({
    #  HM_DATE <- unlist( strsplit(html_text(read_html(x = input$logfile)), '\n'))
    # filename <- "test"# basename(input$logfile) 
    print("Loading, be patient...")
    ldata <- compact(lapply(make_date_list(start=input$start, end=input$end,
                            by=input$by, path=input$path, prefix=input$prefix, 
                            postfix=input$postfix),
                            get_data) )  

    rows1 <- sapply(ldata, function(x)  nrow(x[[1]]) )
    rows2 <- sapply(ldata, function(x)  nrow(x[[2]]) )
    expected <- max(rows1)
    ldata[rows1 < expected | rows1 < expected] <- NULL
    compact(ldata)
    
    spectral <- as_tibble(sapply(names(ldata[[1]][[1]]), function(x) 
                              rowMeans(sapply(ldata, function(y) y[[1]][[x]]))
                               ))
    updateSelectInput(session, "spnorms",
           choices = attr( spectral,"names")) # current selection

    gridpoint <- as_tibble(sapply(names(ldata[[1]][[2]]), function(x) 
                              rowMeans(sapply(ldata, function(y) y[[2]][[x]]))
                             ))
    updateSelectInput(session, "gpnorms",
           choices = attr( gridpoint,"names")) # current selection
     
     # Save metdata and norms into RDS
      meta  <- tibble(prefix=input$prefix, postfix=input$postfix, path=input$path, 
                start=input$start, end=input$end, by=input$by)
     RDS_dir <- paste(here(),"RDS/",sep="/")
     filename <- paste( #paste( tail(unlist(strsplit(meta$path,"/")),n=1),
                        paste(basename(meta$path),
                        #      basename(dirname(meta$path)),
                        meta$prefix,
                        meta$start,meta$end,meta$by,sep="_"),
                        ".rds",sep="")
     object <- list(meta=meta, gridpoint=gridpoint, spectral=spectral)     
     names(object) <- c("meta", "gridpoint", "spectral")
     saveRDS(object, paste(RDS_dir,filename,sep=""))
        
  #})    
  #print("Boarding completed")

  output$plot <- renderPlot({
    if (v$doPlot == FALSE) return()
       if (input$tabset == "Spectral norms") {
        specimen <- spectral
        Y <- input$spnorms
        linecolour <- "blue"      

      

      } else if (input$tabset == "Grid point norms"){
        specimen <- gridpoint
        Y <- input$gpnorms
        linecolour <- "red"
      } 
    
       p <- ggplot() + 
        geom_line(data = specimen, aes(x = NSTEP, y = .data[[Y]]), 
                                       colour = linecolour) +
        ylab(Y) + 
        ggtitle(paste( input$path,input$prefix,"yyyymmddhh",input$postfix,"\n",
                  input$start,"-",input$end," by ",input$by," hours", sep=""))
       if (input$showzero =="yes"){
          p <- p + expand_limits(x = 0, y = 0)}
       p
  }) #RenderPlot
   print("Loading completed")
} ) #RenderText
}
  
```

Read html logfile produced by Harmonie-arome into memory as text. Files can be local paths or urls. Not used, can be handy for debugging etc.

```{r}
#Read html logfile produced by Harmonie-arome into memory as text. Files can be local paths or urls. Not used, can be handy for debugging etc.
#logfile <- '/home/forteliu/Bologna/hm_home/cy46_NYLAND750/archive/log/HM_Date_2022081500.html'
if (FALSE) {
logfile <- "https://metcoop.smhi.se/monitoring/msms/data/meps/HM_Date_2023030912_1_se.html"
logfile <- "/ec/res4/scratch/sbjb/hm_home/mc_preop_baseline/archive/log/HM_Date_2023090412.html"
HM_DATE <- unlist( strsplit(html_text(read_html(x = logfile, encoding="UTF-8")), '\n'))
specimen <- get_cost_functions(HM_DATE)
}
```

Save the tibbles into their respective rds files (not in use)

```{r}
#Save the tibbles into their respective rds files (this is not in use)
#RDS_dir <- "/home/forteliu/Datafiles/RDS/"
#object <- c(meta, gpnorms, spnorms)
#saveRDS(gpnorms, paste(RDS_dir, basename(logfile), ".gpnorms.rds",sep=""))
#saveRDS(spnorms, paste(RDS_dir, basename(logfile), ".spnorms.rds",sep="")) 

```

Run the application. Do this by clicking on the one to the left of the two symbols to execute all chunks above the present, then click on the one to the right to execute and open shiny.

```{r }
# Run the application 
shinyApp(ui = ui, server = server)

```
